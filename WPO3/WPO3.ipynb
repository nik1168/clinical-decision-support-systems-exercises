{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7747bad258d60cab37e9b1e227b40fe4",
     "grade": false,
     "grade_id": "cell-5983e95001baf4dd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Health Information Systems and Decision Support Systems\n",
    "## WPO 3: Data-driven systems  (06/03/20)\n",
    "***\n",
    "*Jakub Ceranka, Pieter Boonen, Jef Vandemeulebroucke* <br>\n",
    "*Department of Electronics and Informatics (ETRO)* <br>\n",
    "*Vrije Universiteit Brussel, Pleinlaan 2, B-1050 Brussels, Belgium*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Insert students names and IDs here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "adcf9e0c05f0a88bf011914349ba8328",
     "grade": false,
     "grade_id": "cell-dc244f69257aecd9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Goal\n",
    "The goal of this practical session is to get an insight into architecture and basic functionalities of an automatic bone cancer detection system using real life medical image dataset of metastatic bone disease patients. Your tasks will involve examining and preprocessing the data, training various classifiers and validating the performance of your system against the ground-truth predictions done manually by an experienced radiologist. Students must send their notebook using the Dropbox functionality of Ufora or Assignment functionality of Canvas before the __19th of March, 2020, midnight. Remember to include the HTML format!.__ The grade from this practical session will contribute to your final grade.\n",
    "Questions: [jceranka@etrovub.be](mailto:jceranka@etrovub.be) \n",
    "***\n",
    "### Metastatic bone disease MRI dataset\n",
    "***\n",
    "#### Bone metastases\n",
    "Cancer that begins in an organ, such as lungs, breast or prostate, and then spreads via blood stream or lymph vessels to the bone is called a __metastatic bone disease__ (MBD). Bone metastases mostly affect axial skeleton, pelvis and upper parts of the femur bones. Patients with advanced breast or prostate cancer have more than 50% chance to develop bone metastases. MBD results in severe bone pain, fractures, spinal cord compression and eventually death.\n",
    "***\n",
    "#### Assessment of treatment response\n",
    "In order to assess the treatment response of a MBD patient over time, the volume and several functional properties of all present bone metastases have to be compared before and after the treatment. This is done using various whole-body medical imaging modalities such as computed tomography, bone scintigraphy or magnetic resonance imaging. A decrease in tumour volume over time usually indicates good response to the treatment. However, the assessment of the response to treatment of bone lesions has been considered difficult and time consuming, compared to lesions involving soft tissues or other organs. Commercial software that enable radiologists to interactively or semi-automatically define individual volumes of interest (VOIs) is beginning to emerge. However, in patients with metastatic bone disease, the number of metastases can be large, making it impractical and extremely time consuming to use such software to evaluate all lesions. This motivates us to work on fully automated segmentation algorithms for the extraction of bone metastases, which could greatly facilitate the disease management for such patients. Additionally, it could also provide valuable tools for studies on large patient populations.\n",
    "***\n",
    "#### Whole-body MRI\n",
    "Whole-body magnetic resonance imaging (MRI) offers excellent sensitivity for the detection of neoplastic cells within the bone marrow using so-called anatomic sequences. Basic sequences, i.e. T1-weighted sequences, provide a high contrast between the low signal intensity of the lesions and the high signal intensity of the surrounding marrow. This contrast enables lesion measurement and has been shown feasible in prostate and breast cancer metastases.\n",
    "Additionally, due to the development of parallel imaging and ultra-fast MRI sequences (i.e. echo-planar imaging), functional sequences can be additionally acquired. The whole-body diffusion-weighted imaging (WB-DWI) showed a great potential in tumour detection [<cite>[1]</cite>](https://www.ncbi.nlm.nih.gov/pubmed/24510426)[<cite>[2]</cite>](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0091779).  Moreover, the technique provides quantitative functional parameters showing early changes after therapy: apparent diffusion coefficient (ADC)[<cite>[3]</cite>](https://radiopaedia.org/articles/apparent-diffusion-coefficient-1) and allows for computations of artificial images: high b-value computed DWI [<cite>[4]</cite>](https://www.ncbi.nlm.nih.gov/pubmed/21852566)\n",
    "***\n",
    "#### Anatomical and functional images\n",
    "![modalities](modalities.png)\n",
    "The above image represents all whole-body MRI image modalities used to characterize bone metastases (marked with red arrows). From the left:\n",
    "- T1 anatomical image (bone metastases are darker than the healthy bone)\n",
    "- B-0 diffusion weighted image (lesions are usually brighter than normal bone)\n",
    "- B-1000 diffusion weighted image (lesions are usually much brighter than normal bone)\n",
    "- ADC map (lesions usually lie within a range of 600 to 1200 voxel intensity value)\n",
    "- B-1500 and B-2000 computed diffusion weighted image (lesions are usually much brighter than normal bone, less false positive high intensity signal (e.g. kidneys, bladder)\n",
    "\n",
    "The following image shows a manual delineation of lesions done by radiologist using T1 anatomy image (superior resolution). Segmentation was mapped on complementary image modalities (B-0, B-1000 and ADC respectively).\n",
    "\n",
    "![lesions_zoom](lesions_zoom.png)\n",
    "***\n",
    "#### Features:\n",
    "The goal of the classification task (binary classification) is to determine if a certain voxel of patient's skeleton corresponds to bone lesion or healthy bone tissue, which will allow to automatically construct a segmentation image highlighting bone metastases. In order to do so, you are provided with a dataset consisting of a list of all voxels of the skeleton tissue from 9 metastatic bone disease patients. \n",
    "\n",
    "Each skeleton voxel has an independent set of features describing its individual properties:\n",
    "- The medical diagnosis label assessed by a radiologist via manual segmentation: *healthy* or *lesion*.\n",
    "- The (x, y ,z) 3D position coordinates. \n",
    "- A set of 5 unique features representing its intensity values across each of 6 different modalities used (T1, B-0, B-1000, ADC, B-1500, B-2000):\n",
    "        a) Intensity of a voxel \n",
    "        b) Mean intensity of a kernel of size 5 around the voxel of interest\n",
    "        c) Median intensity of a kernel of size 5 around the voxel of interest\n",
    "        d) Maximum intensity of a kernel of size 5 around the voxel of interest\n",
    "        e) Minimum  intensity of a kernel of size 5 around the voxel of interest\n",
    "        \n",
    "All features were computed automatically, using automatic image processing algorithms. In total the dataset consists of 291776 voxels labeled *healthy* or *lesion*. The dataset is balanced and has a 50-50 distribution: 145888 *healthy* voxels, 145888 *lesion* voxels.\n",
    "\n",
    "You can read more about the way the features were extracted in [<cite>[5]</cite>](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/9414/1/Spinal-focal-lesion-detection-in-multiple-myeloma-using-multimodal-image/10.1117/12.2081990.short?SSO=1), where authors have used a similar feature extraction method. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e23810ad2fd37b5789a2636c9df47336",
     "grade": false,
     "grade_id": "cell-92aec094a0fce0ad",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 1: Prepare the data for Machine Learning Algorithms  \n",
    "\n",
    "Before doing any manipulations to the data, lets inspect it first. Open metastases features of the first patient and have a look at the data using the head() and info() commands. In order to create an effective training dataset, several preprocessing steps have to be performed. The following steps have to be performed for each patient's data individually. \n",
    "__Hint__: it is useful to use a for loop, performing all of the following steps for each patient (1-9). \n",
    "<br><br>\n",
    "1. __Removing useless columns.__ Have a look at the *head()* of the dataframe. Some columns are not needed at your classifier training stage since they do not hold any relevant information. Remove the column with the ordinal number and all three positional columns (X,Y,Z). Your dataset should be 4 columns narrower in shape now.\n",
    "<br><br>\n",
    "2. __Handling missing data.__ Most machine learning algorithms cannot work with missing features, so let's take care of that. Use panda's function *info()* to check if any feature has missing 'not-a-number' values. You can solve that problem easily by either dropping those lines with a *dropna()* function or setting them to zero, mean or median of the feature column (function *fillna()*). Because the more the data, usually, the better the performance of the classifier, lets substitute the missing values with the median of the column in which the values are missing.\n",
    "<br><br>\n",
    "3. __Separation of data.__ Separate the training set from the labels (classes). Save the training set as X and label column as Y.\n",
    "<br><br>\n",
    "4. __Concatenation of features.__ Inside the for loop, concatenate all dataframes. __Hint__: In order to append all patient's data, create two empty dataframes (intensity train dataset and label column) and copy column names from the first patient's dataframe. Append empty dataframes with new data with every iteration of the loop. The function should return a formated intensity dataframe and Y dataframe containing the label column. \n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will inspect the metastases features of the first patient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use df_p1 as an abbreviation of \"data frame patient 1\"\n",
    "path_p1 = \"Data/Patient_1/Features_Balanced.csv\"\n",
    "df_p1 = pd.read_csv(path_p1, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>T1</th>\n",
       "      <th>Mean_T1</th>\n",
       "      <th>Median_T1</th>\n",
       "      <th>Max_T1</th>\n",
       "      <th>Min_T1</th>\n",
       "      <th>B0</th>\n",
       "      <th>Mean_B0</th>\n",
       "      <th>Median_B0</th>\n",
       "      <th>Max_B0</th>\n",
       "      <th>...</th>\n",
       "      <th>Min_B2000</th>\n",
       "      <th>ADC</th>\n",
       "      <th>Mean_ADC</th>\n",
       "      <th>Median_ADC</th>\n",
       "      <th>Max_ADC</th>\n",
       "      <th>Min_ADC</th>\n",
       "      <th>Position_X</th>\n",
       "      <th>Position_Y</th>\n",
       "      <th>Position_Z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>864.664</td>\n",
       "      <td>863.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>81.872</td>\n",
       "      <td>61.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>905.912</td>\n",
       "      <td>873.0</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>15</td>\n",
       "      <td>888</td>\n",
       "      <td>264</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>622.0</td>\n",
       "      <td>759.960</td>\n",
       "      <td>778.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>97.400</td>\n",
       "      <td>95.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>907.400</td>\n",
       "      <td>758.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>15</td>\n",
       "      <td>892</td>\n",
       "      <td>222</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>781.800</td>\n",
       "      <td>778.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>102.248</td>\n",
       "      <td>88.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>890.144</td>\n",
       "      <td>868.0</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16</td>\n",
       "      <td>296</td>\n",
       "      <td>264</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>728.0</td>\n",
       "      <td>612.944</td>\n",
       "      <td>607.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1140.992</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>2056.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>2130.600</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>17</td>\n",
       "      <td>287</td>\n",
       "      <td>248</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>953.0</td>\n",
       "      <td>780.696</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>193.384</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>889.504</td>\n",
       "      <td>822.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>17</td>\n",
       "      <td>303</td>\n",
       "      <td>249</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      T1  Mean_T1  Median_T1  Max_T1  Min_T1      B0   Mean_B0  \\\n",
       "0           0   653.0  864.664      863.0  1150.0   517.0    63.0    81.872   \n",
       "1           1   622.0  759.960      778.0  1024.0   442.0    59.0    97.400   \n",
       "2           2  1047.0  781.800      778.0  1047.0   493.0    67.0   102.248   \n",
       "3           3   728.0  612.944      607.0   819.0   395.0  1853.0  1140.992   \n",
       "4           4   953.0  780.696      800.0  1023.0   483.0    99.0   193.384   \n",
       "\n",
       "   Median_B0  Max_B0  ...  Min_B2000     ADC  Mean_ADC  Median_ADC  Max_ADC  \\\n",
       "0       61.0   454.0  ...        4.0   787.0   905.912       873.0   1773.0   \n",
       "1       95.0   227.0  ...        5.0   758.0   907.400       758.0   1755.0   \n",
       "2       88.0   462.0  ...        5.0   862.0   890.144       868.0   1807.0   \n",
       "3     1326.0  2056.0  ...        0.0  1957.0  2130.600      1946.0   4004.0   \n",
       "4       91.0  1271.0  ...        1.0   326.0   889.504       822.0   2377.0   \n",
       "\n",
       "   Min_ADC  Position_X  Position_Y  Position_Z    class  \n",
       "0    197.0          15         888         264  healthy  \n",
       "1    427.0          15         892         222  healthy  \n",
       "2     45.0          16         296         264  healthy  \n",
       "3    558.0          17         287         248  healthy  \n",
       "4    167.0          17         303         249  healthy  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying the head function we can see that there is an \"Unnamed\" column as well as the X,Y and Z coordinates of the voxel. These three features do not contribute any relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1368 entries, 0 to 1367\n",
      "Data columns (total 35 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    1368 non-null   int64  \n",
      " 1   T1            1368 non-null   float64\n",
      " 2   Mean_T1       1368 non-null   float64\n",
      " 3   Median_T1     1368 non-null   float64\n",
      " 4   Max_T1        1368 non-null   float64\n",
      " 5   Min_T1        1368 non-null   float64\n",
      " 6   B0            1368 non-null   float64\n",
      " 7   Mean_B0       1368 non-null   float64\n",
      " 8   Median_B0     1368 non-null   float64\n",
      " 9   Max_B0        1368 non-null   float64\n",
      " 10  Min_B0        1368 non-null   float64\n",
      " 11  B1000         1368 non-null   float64\n",
      " 12  Mean_B1000    1368 non-null   float64\n",
      " 13  Median_B1000  1368 non-null   float64\n",
      " 14  Max_B1000     1368 non-null   float64\n",
      " 15  Min_B1000     1368 non-null   float64\n",
      " 16  B1500         1368 non-null   float64\n",
      " 17  Mean_B1500    1368 non-null   float64\n",
      " 18  Median_B1500  1368 non-null   float64\n",
      " 19  Max_B1500     1368 non-null   float64\n",
      " 20  Min_B1500     1368 non-null   float64\n",
      " 21  B2000         1368 non-null   float64\n",
      " 22  Mean_B2000    1368 non-null   float64\n",
      " 23  Median_B2000  1368 non-null   float64\n",
      " 24  Max_B2000     1368 non-null   float64\n",
      " 25  Min_B2000     1368 non-null   float64\n",
      " 26  ADC           1368 non-null   float64\n",
      " 27  Mean_ADC      1368 non-null   float64\n",
      " 28  Median_ADC    1368 non-null   float64\n",
      " 29  Max_ADC       1368 non-null   float64\n",
      " 30  Min_ADC       1368 non-null   float64\n",
      " 31  Position_X    1368 non-null   int64  \n",
      " 32  Position_Y    1368 non-null   int64  \n",
      " 33  Position_Z    1368 non-null   int64  \n",
      " 34  class         1368 non-null   object \n",
      "dtypes: float64(30), int64(4), object(1)\n",
      "memory usage: 374.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_p1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1368, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>T1</th>\n",
       "      <th>Mean_T1</th>\n",
       "      <th>Median_T1</th>\n",
       "      <th>Max_T1</th>\n",
       "      <th>Min_T1</th>\n",
       "      <th>B0</th>\n",
       "      <th>Mean_B0</th>\n",
       "      <th>Median_B0</th>\n",
       "      <th>Max_B0</th>\n",
       "      <th>...</th>\n",
       "      <th>Min_B2000</th>\n",
       "      <th>ADC</th>\n",
       "      <th>Mean_ADC</th>\n",
       "      <th>Median_ADC</th>\n",
       "      <th>Max_ADC</th>\n",
       "      <th>Min_ADC</th>\n",
       "      <th>Position_X</th>\n",
       "      <th>Position_Y</th>\n",
       "      <th>Position_Z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1368 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     T1  Mean_T1  Median_T1  Max_T1  Min_T1     B0  Mean_B0  \\\n",
       "0          False  False    False      False   False   False  False    False   \n",
       "1          False  False    False      False   False   False  False    False   \n",
       "2          False  False    False      False   False   False  False    False   \n",
       "3          False  False    False      False   False   False  False    False   \n",
       "4          False  False    False      False   False   False  False    False   \n",
       "...          ...    ...      ...        ...     ...     ...    ...      ...   \n",
       "1363       False  False    False      False   False   False  False    False   \n",
       "1364       False  False    False      False   False   False  False    False   \n",
       "1365       False  False    False      False   False   False  False    False   \n",
       "1366       False  False    False      False   False   False  False    False   \n",
       "1367       False  False    False      False   False   False  False    False   \n",
       "\n",
       "      Median_B0  Max_B0  ...  Min_B2000    ADC  Mean_ADC  Median_ADC  Max_ADC  \\\n",
       "0         False   False  ...      False  False     False       False    False   \n",
       "1         False   False  ...      False  False     False       False    False   \n",
       "2         False   False  ...      False  False     False       False    False   \n",
       "3         False   False  ...      False  False     False       False    False   \n",
       "4         False   False  ...      False  False     False       False    False   \n",
       "...         ...     ...  ...        ...    ...       ...         ...      ...   \n",
       "1363      False   False  ...      False  False     False       False    False   \n",
       "1364      False   False  ...      False  False     False       False    False   \n",
       "1365      False   False  ...      False  False     False       False    False   \n",
       "1366      False   False  ...      False  False     False       False    False   \n",
       "1367      False   False  ...      False  False     False       False    False   \n",
       "\n",
       "      Min_ADC  Position_X  Position_Y  Position_Z  class  \n",
       "0       False       False       False       False  False  \n",
       "1       False       False       False       False  False  \n",
       "2       False       False       False       False  False  \n",
       "3       False       False       False       False  False  \n",
       "4       False       False       False       False  False  \n",
       "...       ...         ...         ...         ...    ...  \n",
       "1363    False       False       False       False  False  \n",
       "1364    False       False       False       False  False  \n",
       "1365    False       False       False       False  False  \n",
       "1366    False       False       False       False  False  \n",
       "1367    False       False       False       False  False  \n",
       "\n",
       "[1368 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p1.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0\n",
       "T1              0\n",
       "Mean_T1         0\n",
       "Median_T1       0\n",
       "Max_T1          0\n",
       "Min_T1          0\n",
       "B0              0\n",
       "Mean_B0         0\n",
       "Median_B0       0\n",
       "Max_B0          0\n",
       "Min_B0          0\n",
       "B1000           0\n",
       "Mean_B1000      0\n",
       "Median_B1000    0\n",
       "Max_B1000       0\n",
       "Min_B1000       0\n",
       "B1500           0\n",
       "Mean_B1500      0\n",
       "Median_B1500    0\n",
       "Max_B1500       0\n",
       "Min_B1500       0\n",
       "B2000           0\n",
       "Mean_B2000      0\n",
       "Median_B2000    0\n",
       "Max_B2000       0\n",
       "Min_B2000       0\n",
       "ADC             0\n",
       "Mean_ADC        0\n",
       "Median_ADC      0\n",
       "Max_ADC         0\n",
       "Min_ADC         0\n",
       "Position_X      0\n",
       "Position_Y      0\n",
       "Position_Z      0\n",
       "class           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will loop over all the patients and do the data pre processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1368, 31)\n",
      "(14136, 31)\n",
      "(30068, 32)\n",
      "(19648, 31)\n",
      "(11204, 31)\n",
      "(18860, 31)\n",
      "(35132, 31)\n",
      "(121610, 31)\n",
      "(39750, 31)\n"
     ]
    }
   ],
   "source": [
    "intensity_train_dataset_dfs = []\n",
    "y_dfs = []\n",
    "for patient_index in range(1,10):\n",
    "    path_patient_file = \"Data/Patient_{0}/Features_Balanced.csv\".format(patient_index)\n",
    "    patient_dataframe = pd.read_csv(path_patient_file, delimiter=',')\n",
    "    \n",
    "    # 1.- Removing useless columns\n",
    "    patient_dataframe = patient_dataframe.drop([\"Position_X\",\"Position_Y\",\"Position_Z\"], axis=1)\n",
    "    patient_dataframe = patient_dataframe.drop(patient_dataframe.columns[0], axis=1)\n",
    "    \n",
    "    # 2.- Handling missing data (repace nan by mean)\n",
    "    patient_dataframe = patient_dataframe.fillna(patient_dataframe.mean())\n",
    "    \n",
    "    #3.- Separation of data\n",
    "    print(patient_dataframe.shape)\n",
    "    X = patient_dataframe.iloc[:,0:30]\n",
    "    y = patient_dataframe.iloc[:,-1]\n",
    "    \n",
    "    # 4.- Concat dataframes\n",
    "    intensity_train_dataset_dfs.append(X)\n",
    "    y_dfs.append(y)\n",
    "\n",
    "patient_dataframe = pd.concat(intensity_train_dataset_dfs, ignore_index=True)\n",
    "y = pd.concat(y_dfs, ignore_index=True)\n",
    "    \n",
    "#     print(\"Patient {0}\".format(patient_index))\n",
    "#     print(patient_dataframe.isnull().sum())\n",
    "#     patient_dataframe.info()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291776, 31)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291776,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1312de7f7ad5c9a262ae8526d6b1b5ae",
     "grade": false,
     "grade_id": "cell-f6c66177f031a4ae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 2: Data visualization \n",
    "\n",
    "Make a scatter plot and a seaborn's kde plot showing relation of the classes (healthy/lesion) for the T1 intensity vs B-1000 intensity.\n",
    "\n",
    "Which plot is better for the visualization of that many datapoints (scatter or kde)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for Task 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b87105beb8be9e5141e0a4764f22b35f",
     "grade": false,
     "grade_id": "cell-4760bf6416fa5c37",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 3: Training classifiers\n",
    "\n",
    "After the data is preprocessed and formated for machine learning purposes, lets train our first classifier. In order to have a reliable and unbiased result of the classifier accuracy, the classifier cannot be trained on the same data, which later is used for validation. Therefore, you have to split your dataset into training and testing data. A quick option is to use Scikit-Learn's __cross-validation__ feature. It performs a K-fold cross-validation: it randomly splits the training set into *K* distinct subsets called folds, then trains and evaluates your classifier model *K* times, picking a different fold for evaluation every time and training on the other *K-1* folds. The result will contain *K* evaluation scores. Additionally, shuffle your data during cross-validation to make sure that you use an equal part of each patient data. __Hint__: [__ShuffleSplit__](http://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics)\n",
    "\n",
    "Declare two classifier models: random forest and K-neighbors classifier and using the function *cross_val_score* calculate the mean of 10-fold cross validation on your feature dataset. Print the obtained scores per classifier, their mean and standard deviation.\n",
    "\n",
    "What is the accuracy score? Which classifier performed best? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for Task 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "109c5599ea06cd60807780543281b8a8",
     "grade": false,
     "grade_id": "cell-e4ad8339fe1b7cbd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 4: Validation of predicted values \n",
    "\n",
    "Based on the results from Task 3, chose the best classifier. Using sklearn __train_test_split__, split the data into 2 sets: the _training_ set and the _test_ set. It is common to use 80% of the data for training and 20% for testing. Train the classifier on the _training_ set and use it to predict the _test_ set. Measure & visualise the perfomance of your classifier using the confusion matrix, the classification report and the ROC curve.\n",
    "__Hint__: Transform the Healthy/Lesion parameters into binary in order to create the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "46dcbdd257a69f42693aaa3dc89137c4",
     "grade": false,
     "grade_id": "cell-22608436d8e1a808",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 5: Optimization of the classifier\n",
    "\n",
    "Optimize your classifier using sklearn __grid search__. Grid optimizes your classifier based on the parameters you want it to experiment with and what values to try out. It uses cross-validation to evaluate all possible combinations of the parameters and values, providing the optimal combinations in the end. For the sake of time, choose 3 parameters you want to optimize. More info on the parameters can be found [__here__](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74). Retrain your optimized classifier and compare performance with the non-optimized classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Code for task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "992ea16c79fef48f18b44de16003734c",
     "grade": false,
     "grade_id": "cell-bf434bbfbb5ecc1b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 6: Segmentation result image\n",
    "\n",
    "It is time to test our machine learning algorithm on a new data, which was not involved in a training stage. You are going to detect bone lesions in a test patient to test the performance of your classifier. After tissue classification, we will create a segmentation image.\n",
    "\n",
    "1. Train the best performing classifier with suitable parameters on the whole dataset of 9 patients (do not use cross validation).\n",
    "\n",
    "2. Have a look at the *Patient_Test* folder. The folder contains information extracted from 3 different frontal slices of the same bone metastases patient. For each slice the following files are given:\n",
    "    - .csv file containing a list of features extracted from every skeleton voxel visible on the slice\n",
    "    - .mhd image file representing T1-anatomy MRI image (slice_T1.mhd)\n",
    "    - .mhd image file representing a ground-truth segmentation image (slice_GT.mhd)\n",
    "    \n",
    "3. Load and plot the T1 image using provided SimpleITK functions. For more information on SimpleITK click [here](http://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/)\n",
    "\n",
    "4. Choose a slice and load a corresponding .csv file. Remove not needed columns and split the dataframe into features, positions and class columns of size 30, 2 and 1 accordingly.\n",
    "\n",
    "5. Using your trained intensity classifier, predict if the voxels from the slice are of a healthy or metastatic bone. Compare your findings with a ground truth vector extracted in point 4. Print classification report.\n",
    "\n",
    "6. Reconstruct segmentation using provided function using obtained predicted classes vector and position data. Plot your result in the overlay with T1 image.\n",
    "\n",
    "7. Repeat for the remaining two slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for task 6\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def loadImage(filename):\n",
    "    image = sitk.ReadImage(filename)\n",
    "    return image\n",
    "\n",
    "def showImage(image):\n",
    "    plt.figure(figsize=(5, 20))\n",
    "    plt.imshow(sitk.GetArrayViewFromImage(image), cmap=plt.cm.Greys_r)\n",
    "\n",
    "def showImageOverlay(image1, image2):\n",
    "    plt.figure(figsize=(5, 20))\n",
    "    plt.imshow(sitk.GetArrayViewFromImage(image1), cmap='gray', interpolation='none')\n",
    "    plt.imshow(sitk.GetArrayViewFromImage(image2), cmap='Reds', alpha=0.3, interpolation='none')\n",
    "    \n",
    "def reconstruct_segmentation_image(predicted, positions, slice_filename):\n",
    "    \n",
    "    # Load slice image and convert to numpy array\n",
    "    slice_image = sitk.ReadImage(slice_filename)\n",
    "    slice_image = sitk.GetArrayFromImage(slice_image)\n",
    "    \n",
    "    # Convert position columns to int type\n",
    "    position = positions.as_matrix()\n",
    "    position = position.astype(int)\n",
    "    \n",
    "    # Create empty slice template\n",
    "    output_seg = np.zeros((slice_image.shape[0], slice_image.shape[1]))\n",
    "    \n",
    "    # Fill in the template using predictions\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == 'healthy':\n",
    "            output_seg[position[i,0],position[i,1]] = 0\n",
    "        else:\n",
    "            output_seg[position[i,0],position[i,1]] = 1\n",
    "    \n",
    "    output_seg = sitk.GetImageFromArray(output_seg)\n",
    "    \n",
    "    return output_seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0d8993ae9e315f72bd2cac85970a608c",
     "grade": false,
     "grade_id": "cell-d69d914a37d5e260",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 7: Extra points\n",
    "\n",
    "Can you further improve the performance of your algorithm?\n",
    "You can modify any step in existing algorithm, starting from data preprocessing, classifier selection (you can choose a completely different one) or fine tuning of its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for task 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
