{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fd435013e3a67ca3115e79dabcd0045a",
     "grade": false,
     "grade_id": "cell-df9b7bcad71e33a2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Health Information Systems and Decision Support Systems\n",
    "## WPO 1: Introduction to data analysis and visualization  (14/02/20)\n",
    "\n",
    "*Jakub Ceranka, Pieter Boonen, Jef Vandemeulebroucke* <br>\n",
    "*Department of Electronics and Informatics (ETRO)* <br>\n",
    "*Vrije Universiteit Brussel, Pleinlaan 2, B-1050 Brussels, Belgium*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Insert students names and IDs here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "139e74448b9c2c1df66fcb43a34e236f",
     "grade": false,
     "grade_id": "cell-f9aa9363ac438c72",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Goal\n",
    "The goal of this practical session is to obtain insight in basic data analysis and data visualization techniques using Jupyter notebook. Basic operations presented today will be very useful during the next practical sessions, where you will need to design and build different decision systems. In this practical session, basic libraries like *pandas*, *matplotlib* and *seaborn* are introduced and applied to the Wisconsis breast cancer data set. Students must send their notebook using Assignment functionality of Canvas (VUB) or Dropbox functionality of Ufora (UGent) using .ipynb __and__ .html format before the end of the __20th of February__ (midnight). All practical sessions are graded. Additionally, a general feedback will be provided in the next practical session. \n",
    "\n",
    "__Hints__ for all practical sessions:\n",
    "- Make sure that the code is pre-compiled and all output is generated correctly before handing in your notebook\n",
    "- Pay attention to the layout of your figures (labels, titles, legends, colors,...)\n",
    "- Chose relevant abbrevations for your variables, make sure your variables are not overwritten\n",
    "- Read all assignments thoroughly\n",
    "***\n",
    "### Jupyter notebook\n",
    "\n",
    "Jupyter notebook is an open-source application that allows editing and running notebook documents via a web browser. Notebook documents contain both computer code (python) and text elements (paragraphs, equations, figures,...). In this way, notebook files can serve as a complete computational record of a session, interleaving executable code with explanatory text, mathematics, and rich representations of resulting objects. Notebooks may be exported to a range of static formats, including HTML, reStructuredText, LaTeX and PDF. Basic functionalities of the Jupyter notebook are presented [here](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Notebook%20Basics.html).\n",
    "***\n",
    "### The breast cancer Wisconsin (diagnostic) data set\n",
    "\n",
    "#### Fine needle aspirate procedure:\n",
    "The dataset consists of features computed from a digitized image of a fine needle aspirate (FNA) of breast mass. For this type of biopsy technique, a thin hollow needle is inserted into an area of abnormal-appearing tissue for sampling cells. This sample is examined under a microscope which is used in the diagnosis of cancer. FNA is generally considered a safe procedure. \n",
    "***\n",
    "#### FNA images:\n",
    "The image below represents a smear of nuclei of benign and malignant breast mass cells. A difference in shape, size and smoothness of cells is visible.\n",
    "\n",
    " ![Image of cells](./FNA_cells.png \"FNA_cells\")\n",
    " \n",
    "[<cite>Sizilio et al. 2012</cite>](https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-11-83) \n",
    "***\n",
    "#### Features:\n",
    "In oder to describe the images with numerical values, which can be easily interpreted by a computer, the features term has to be introduced. Features describe characteristics of the nuclei present in the microscopic image. Usually, the more of the independent features describing the image, the better.\n",
    "\n",
    "Each cell nuclei has an independent set of features describing its individual properties:\n",
    "- ID number of the patient from which the cell was collected.\n",
    "- The medical diagnosis label assessed by a histologist/oncologist: Malignant or Benign. \n",
    "- The mean, standard deviation and the 3 worst values of 10 features describing mathematical properties of a cell were computed. This included:\n",
    "        a) radius (distance from center to points on the perimeter)\n",
    "        b) texture (standard deviation of gray-scale values)\n",
    "        c) perimeter\n",
    "        d) area\n",
    "        e) smoothness (local variation in radius lengths)\n",
    "        f) compactness (perimeter^2 / area - 1.0)\n",
    "        g) concavity (severity of concave portions of the contour)\n",
    "        h) concave points (number of concave portions of the contour)\n",
    "        i) symmetry\n",
    "        j) fractal dimension  (measure of cells self-similarity)\n",
    "  \n",
    "Some features were computed automatically, using automatic image processing algorithms, others acquired manually by medical experts. Microscopic images of 569 cells were analysed and labeled as benign or malignant. \n",
    "Class distribution: 357 benign, 212 malignant.\n",
    "***\n",
    "### Libraries\n",
    "\n",
    "During this practical session, multiple libraries will be used for the analysis and visualization of data. You can use different version of libraries, however we recommend the following build:\n",
    "\n",
    "- [__Pandas__](https://pandas.pydata.org/pandas-docs/stable/tutorials.html):     high performance library used for processing data structures and data analysis. __V 0.22.0__ \n",
    "- [__Numpy__](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html):      library used for scientific computing containing N-dimensional arrays, functions and Fourier transform. __V 1.13.3__ \n",
    "- [__Sci-kit Learn__](http://scikit-learn.org/stable/index.html):     Simple and efficient tools for machine learning and data analysis. __V 0.19.1__ \n",
    "- [__Matplotlib__](https://matplotlib.org/users/pyplot_tutorial.html): plotting library used for the visualization of data from python. __V 2.1.0__ \n",
    "- [__Seaborn__](https://seaborn.pydata.org/):    visualization library based on matplotlib, providing a high-level interface for drawing attractive statistical graphics. __V 0.8.1__ \n",
    "\n",
    "To import any external library, you need to import it using the **import** statement followed by the name of the library and the shortcut. The following code imports Pandas and represents it as 'pd'. You can additionally check for the module version using __version__ command. Information on updating the libraries using Anaconda can be found  [here](http://conda-test.pydata.org/docs/examples/update.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "47ae42137c4a1e922f27db6e527cc11b",
     "grade": false,
     "grade_id": "cell-9ffb82fb313cfa76",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6142b137f9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92a44e50499bf44a6f6547a83e6699f1",
     "grade": false,
     "grade_id": "cell-ad703a062149a68b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 1: Importing data  \n",
    "\n",
    "Provided dataset is represented as the comma-separated values (.csv) file which stores the tabular data in plain text.\n",
    "\n",
    "Load the dataset (dataWisconsinBreast.csv) as the dataframe object using Panda's __read_csv__ function and have a look at the data using the __head()__ command. By default, the statement will print out top 5 rows of the dataset.\n",
    "The __info()__ method is useful to get a quick description of the data, in particular the total number of rows, and each feature's type and number of non-null values.\n",
    "\n",
    "Hint: To use a command from a library, type the abbrevation of the library followed by a dot and the function  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3ca744ee191d3707f0facde02f211a52",
     "grade": false,
     "grade_id": "cell-c61926438dee270c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 2: Dataset preprocessing\n",
    "\n",
    "Lets have a closer look at the dataset. Using inbuilt Pandas function check if the dataset's shape matches with number of cells (rows) and features (columns) provided in the section 'Features'. \n",
    "\n",
    "__Hint: Something on the index for a column?__\n",
    "\n",
    "Print the __head()__ of the dataframe again. The first column of the dataset is a random patients ID number which does not bring any clinically relevant information to the dataset. The last column represents NaN (not a number values). Remove these columns from the dataset and check if the shape has decreased accordingly. Additionally, remove all features which do not represent the mean (\\_mean) value and assign it to the new dataframe.\n",
    "\n",
    "The next step is to normalize (min-max scaling) the values. Most machine learning algorithms don't perform well when the numerical input values have very different scales. To rescale the data, we subtract the minimum from every value and divide by the maximum minus the minimum ($\\frac{value-min}{max-min}$). \n",
    "\n",
    "Hint: Use __MinMaxScaler__ from __sklearn__ for the normalization. \n",
    "\n",
    "Now that the values are all normalized, the name of the features should be changed as well. Add *_N* after each feature using __rename()__ .\n",
    "\n",
    "Hint: Printing a list with the names of the features will save you some time \n",
    "\n",
    "You can see that the dataset 'diagnosis' column has either M or B symbol, representing respectively malignant or benign cancer classification label. Split the dataframe into two datasets, representing all benign and malignant rows of features. Does the shapes of new datasets match the dataset class distribution? \n",
    "\n",
    "Save all three new datasets (cropped with B and M, cropped B and cropped M) as the .csv files in your working directory. Use these normalized datasets for the next tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7bf755797d604acfe485e239b5618fc9",
     "grade": false,
     "grade_id": "cell-bd21bc3dfb2a958d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 3: Dataset statistics\n",
    "\n",
    "In order to understand the differences and behavior of the data we need to calculate basic statistical values of features. Calculate and print the mean, median, standard deviation and 25th, 75th percentile of the both: malignant and benign dataset for concavity_mean feature on the same figure. \n",
    "\n",
    "Using *pandas* and *matplotlib* library prepare a boxplot of the distribution of the mean radius feature for benign and malignant cells (__Hint:__ concatenate columns of interest and use pandas function boxplot()). \n",
    "\n",
    "describe() method shows a summary of the numerical attributes for all features.\n",
    "\n",
    "Hint: In order to plot directly in Jupyter notebook use the following command: %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "43fe0229adf24d2f1042642535e91c09",
     "grade": false,
     "grade_id": "cell-1d67f212185a28e7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Can you already spot the differences in data distributions between benign and malignant cancer? What conclusions regarding the size and shape of malignant vs benign cells can be drawn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "83154512dc8612868b1a40c6d52bf125",
     "grade": false,
     "grade_id": "cell-8eb3d8d7afcecb2e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 4: Visualization of nuclei features\n",
    "\n",
    "Another quick way to get a feel of the type of data you are dealing with is to plot a histogram for each numerical attribute. A histogram shows the number of instances (on the vertical axis) that have a given value range (on the horizontal axis). Using *matplotlib* plot a histogram of a mean radius of malignant cancer cells. On the same figure add a histogram (using a different color) of benign cancer cells radius (Hint: use *matplotlib* function hist() ). Do the histograms correlate with each other?\n",
    "\n",
    "Histogram is a great tool to visualize the distribution of a single feature. However, often a dataset consists of several features and therefore another way of visualization has to be used.\n",
    "\n",
    "A 2D scatterplot shows a relation between two features. Scatterplots are very often used to get a feeling of the data and work as a help tool for choosing a correct design of decision system which you will build during the next practical sessions.\n",
    "\n",
    "Using *matplotlib*, plot on the same figure the relation of the radius_mean feature in function of the texture_mean feature for benign and malignant cases. Mark classes with different color and provide a legend box.\n",
    "\n",
    "Scatterplots give a possibility to analyse the trends and relations between different features. Looking at the plotted scatterplot, you can see that there seem to be a linear relation between radius and texture. Lets try to find it.\n",
    "\n",
    "Using linear regression from Sci-Kit learn toolbox, fit a linear function and plot it on the same scatterplot. Give the formula of the linear function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "339844b597d5d2582bea7ba66115b035",
     "grade": false,
     "grade_id": "cell-7c5078d9654ef528",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "***\n",
    "### Task 5: High-level visualization\n",
    "\n",
    "A scatter plot is a good tool to visualize the distribution of values for small number of instances. However, with very large numbers of instances, all plotted points tent to become inseparable, forming one large cluster of the same color intensity. That issue can be solved by introduction of density plots. Density plot represents data in the same way as the scatterplot, but it changes its density dependent on the number of points in its vicinity. Using *seaborn* library and *kdeplot* function, plot a density plot of the same features (radius in function of texture) for two class labels (benign and malignant) on the same figure. You can easily see that it is much easier now to interpret and separate features.\n",
    "\n",
    "You have plotted the relation between two features now, but what about all of the others. They probably contain additional relevant information for better understanding of the dataset. *Pandas* library provides an inbuilt function *scatter_matrix*, which shows a relations between all inputed features simultaneously. Use a complete dataset to create a scatter_matrix plot. \n",
    "\n",
    "Additionally to the graphical representation of feature pairs, numbers can be generated too. Use *pandas* *corr()* function to investigate correlations of radius_mean feature.\n",
    "What can you say about the relation between radius_mean against different features? Are some features dependent on another? If so, which? Is it worth to use all of the features in your future machine learning system, why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3570d00a86dba471e6560e96b5d65e6d",
     "grade": false,
     "grade_id": "cell-975b3e4489afb8ae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "You can now see the features distribution, but we can not distinguish which point in the provided scatter matrix corresponds to which class. Using *seaborn's pairplot* function print the scatter matrix of radius, texture and concavity for malignant and benign cells.\n",
    "\n",
    "Could you print the same plot (radius, texture & concavity for malignant and benign cells) but instead of a seaborn scatterplot matrix (pairplot) use density distribution matrix (kdeplot matrix)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2748aee5b9893da658819bffa52424fb",
     "grade": false,
     "grade_id": "cell-d3475490f54c3d47",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Task 6: Validation of classifier's performance \n",
    "Load prediction.csv file. The file stores support-vector machine classifier results for each instance in the dataset (classes malignant or benign). Inspect the prediction dataframe. Extract a column predicted from the prediction.csv dataset and column 'diagnosis' from the initial dataset (dataWisconsinBreast.csv) and store them in new dataframes. \n",
    "\n",
    "We are now going to assess the performance of the classifier. Write a python function counting and returning false positive, false negative, true positive and true negative instances. Using obtained statistical values, calculate accuracy, sensitivity, specificity of the classifier. \n",
    "\n",
    "Scikit-learn library provides functions such as *metrics.classification_report*, which calculate and printout the same measures. See the Classification metrics section of the user guide for further details. Does the output of the scikit-learn functions match the ones calculated by you?\n",
    "\n",
    "Briefly describe the difference between calculated measures. \n",
    "During classification of breast biopsies, it is highly important not to miss a malignant case. In other words, we do not want our classifier to classify malignant cell as benign case. The performance of the classifier can be optimized towards such behavior. Which statistical measure should we optimize (increase) in order to decrease these wrong classifications as much as possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
